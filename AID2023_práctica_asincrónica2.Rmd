---
title: "Clase 2 asincr√≥nica: An√°lisis Multivariado"
author: "Pr√°ctico AID 2024"
date: "25/05/2024"
output:
  html_document:
    toc: yes
    toc_float: yes
    df_print: paged
---

Esta notebook les presenta una serie de estrategias que pueden utilizarse para analizar datos multivariados (varias features/variables). Principalmente se utiliza la librer√¨a ggplot para graficar.


## **Cargo librer√≠as**
```{r librerias, warning=F, message=F, warn.conflicts=FALSE}
library(tidyverse)
library(viridisLite)
library(openintro)
library(GGally)
library(corrr)
library(knitr)
library(aplpack) #caras chernoff
library(corrplot)
library(RColorBrewer)
library(scatterplot3d)
library(Hmisc)
library(knitr)
library(ggmosaic)
library(tidymodels)
library(yardstick)
library(ggpubr)
library(fmsb)
library(broom)
library(robustbase)
library(gsheet)
library(patchwork)
library(xlsx)
library(readxl)
library(ggcorrplot)
library(scatterplot3d)
```


La data se carga desde un archivo guardado en un Drive de Google. En las distintas clases les vamos presentando distintas alternativas para que tengan modelos de sintaxis para recuperar informaci√≥n de distintas fuentes.

## **Cargo datos**
<span style="color:blue"> BD de IMC infantil </span>
```{r data, warning=FALSE,message=F, warn.conflicts=FALSE}
#url de la tabla IMCinfantil que se us√≥ para la clase pr√°ctica nro 1
url <- 'https://docs.google.com/spreadsheets/d/1tnxeu-BlbOOaiF9E7HHuuk4-hxgOLHXM' 

# La tabla del url tiene "," como separadores decimales y si se abre directamente desde el url, malinterpreta los n√∫meros -> soluci√≥n: lo abro como texto, cambio "," a "." y luego transformo el dato al tipo num√©rico
data <- read.csv(text=gsheet2text(url, format='csv'))
# muto las variables de las columnas 4-7, y les reemplazo la coma por un punto
data <- data %>% mutate_at(vars(colnames(data[4:7])), ~ str_replace(., ",", "."))
# paso a formato num√©rico
data[c(2,4:8)] <- sapply(data[c(2,4:8)], as.numeric)
```

## **Estilo general para los gr√°ficos**

Este paso es totalmente opcional. En este caso, se define una variable llamada **theme** en la que se definen varios par√°metros de dise√±o/estilo de los gr√°ficos ggplot. Esto hace que cada vez que yo grafique, pueda llamar a "theme" sin tener que escribir todo lo que est√° m√°s abajo, y se respete el mismo estilo para todos los gr√°ficos (ejemplo, t√≠tulo en negrita e it√°lica, fondo blanco, etc...)

```{r theme general}
theme <- theme(text = element_text(size=10),
               plot.title = element_text(size = 12, face = "bold.italic", hjust = 0.5), 
               axis.title.x = element_text(size = 10, face="bold", colour='black'),         
               axis.title.y = element_text(size = 10, face="bold"),
               panel.border = element_blank(),
               panel.grid.major = element_blank(),
               panel.grid.minor = element_blank(), 
               legend.title = element_text(face="bold"))
```

# 1) An√°lisis de vectores de posici√≥n y escala

En la base de datos cargada (variable **data**), yo tengo un dataframe de 150 observaciones y 9 variables. 

_colnames(data)_ les dice el nombre de las mismas --> ["PACIENTE", "EDAD", "SEXO", "PESO", "TALLA", "IMC", "PIMC", "CC", "CatPeso"]

De estas columnas la 3 (SEXO) y la 9 (CatPeso) son variables categ√≥ricas, por lo que no tiene sentido realizar un an√°lisis de posici√≥n y escala para las mismas. Adem√°s la columna 1 (PACIENTE) es una columna identificatoria de la observaci√≤n, por lo que no tiene sentido considerarla para el an√°lisis (es como tener el DNI... de qu√© me sirve tener el promedio de los DNIs? no dice nada del comportamiento del dataset!)

Un an√°lisis de posici√≥n y escala es b√°sicamente calcular la media o mediana del dataset, as√≠ como el desv√≠o.

Cada observaci√≥n (fila) tendr√° un vector caracter√≠stico de variables num√©ricas:
        
        ej obs_1: [ valor_edad_1, valor_peso_1, valor_talla_1, valor_imc_1, ...... ]
           obs_2: [ valor_edad_2, valor_peso_2, valor_talla_2, valor_imc_2, ...... ]
         
Calcular el vector de posici√≥n para el dataset **data** puede realizarse con el siguiente c√≥digo:

```{r vectores1}
# me quedo s√≥lo con las variables num√©ricas
vector_medias <- apply(data[,c(2,4:8)], 2, mean) # aqu√≠ estoy aplicando la funci√≥n mean a data... (considerando todas las filas pero s√≥lo las columnas c(2,4:8) (columnas 2, 4 a 8... se excluye 1, 3 y 9 porque no son num√©ricas)).
# el n√∫mero 2 que se encuentra antes de "mean" indica que ese promedio se realizar√° sobre las columnas. Si hubiera un 1, es sobre las filas. Indicar que aplique la funci√≤n "mean" por columna har√° que se calcule la media para todos los valores de EDAD de todas las observaciones, despu√©s lo mismo para PESO.... es decir que mi vector de medias tendr√° tantos valores como columnas haya.

vector_medias #(comportamiento medio)

vector_sd <- apply(data[,c(2,4:8)], 2, sd)
round(vector_sd,2) #redondeo a 2 decimales
```


# 2) An√°lisis de correlaci√≥n y covarianza
*An√°lisis exploratorio superficial, para analizar las categor√≠as de cada variable*

En los siguientes chunks se presenta un an√°lisis gr√°fico de correlaci√≥n lineal entre las variables. Hay distintos paquetes y formas de calcularlo. 

```{r corr y cov}
# Primeras 5 filas del dataset
head(data,5)
# Resumen variables
str(data) 
# Guardo el nombre de las variables num√©ricas
vars_numericas <- colnames(data %>% select(where(is.numeric))) 

# Indico que la variable "CatPeso" es un factor, y ordeno los niveles 
# (el orden por default es alfab√©tico)
data$CatPeso <- factor(data$CatPeso, levels=c('D','N','SO','OB'))
```
La base de datos posee 7 variables num√©ricas, y 2 variables categ√≥ricas de 150 registros. La variable SEXO es dicot√≥mica nominal, y la variable categor√≠a peso es ordinal. 

*Correlaci√≥n de las variables num√©ricas*
```{r corr graphs, include=T, results=T}
# cambiamos una variable para que correlacione en forma negativa con las restantes 
# SOLO CON FINES DID√ÅCTICOS! 
data$CC=max(data$CC)-data$CC 

# 3 maneras equivalente de generar una sub-base que posea s√≥lo variables num√©ricas 
bd_numericas <- data[c('EDAD','PESO','TALLA','IMC','PIMC','CC')] #selecciono por nombre de columna
bd_numericas <- data[c(2,4:8)] #selecciono por √≠ndice de columna
bd_numericas <- data %>% select(all_of(vars_numericas),-PACIENTE) #utilizando paquete dplyr y funci√≥n select

#Matriz de correlaci√≥n
M <- cor(bd_numericas) 
#Matriz de varianza y covarianza
V <- cov(bd_numericas) #equivalente: var(bd_numericas)

# representa la matriz de correlaciones mediante c√≠rculos
# C√≠rculos rojos indican correlaci√≤n negativa, y c√≠rculos azules indican correlaci√≥n positiva. Cuanto m√°s grande es el radio del c√≠rculo, mayor es el valor absoluto de la correlaci√≥n.
corrplot(M,method="circle") # opciones de par√°metro METHOD: square / ellipse / number / shade / pie
# representa la matriz de correlaciones mediante elipses y s√≥lo en sector superior
# Elipses rojas indican correlaci√≤n negativa, y elipses azules indican correlaci√≥n positiva. Cuanto m√°s "flacos" son los elipses, mayor es el valor absoluto de la correlaci√≥n.
corrplot(M,method="ellipse", type="upper") # opci√≥n: lower
corrplot.mixed(M,lower="circle", upper="shade") # permite combinaciones de estilos por bloques

# ggcorrplot es un m√©todo derivado de ggplot en el que uno le indica la matr√≠z de correlaci√≥n y en p.mat le indica si quiere que calcule el p-valor. Cuando aparece una X, la correlaci√≥n no es significativa estad√≠sticamente
ggcorrplot(M,hc.order = TRUE, outline.col = "white", p.mat=cor_pmat(bd_numericas)) + theme + 
  labs(title='Correlograma', x='Variable', y=NULL) #method= 'circle'/ type=.../lab=T
```


Hay un m√©todo s√∫per interesante de la librer√≠a GGally llamada ggpairs que presenta un an√°lisis m√°s abarcativo de la relaci√≥n entre las variables num√©rcias. Presenta la distribuci√≥n de cada variable (en la diagonal), un scatterplot de la relaci√≥n de una variable con otra, y luego un an√°lisis de correlaci√≥n (con la significancia asociada). Por default, la correlaci√≥n calculada es la correlaci√≥n lineal de Pearson, pero puede cambiarse.

```{r ggpairs, include=T, results=T}
ggpairs(bd_numericas,progress = F) + theme +
  labs(title= 'Descripci√≥n de variables num√©ricas en la base de datos', 
       x = 'Variable', y = 'Variable') 
```




*Correlaci√≥n de las variables num√©ricas y asociaci√≥n de variables realizando apertura por sexo*

Se pueden agregar variables categ√≥ricas al graficar (en el siguiente caso, se realiza una apertura por sexo)

```{r ggpairs by sexo, include=T, results=T}
bd_numericas_sexo <- data %>%select(SEXO, all_of(vars_numericas),-PACIENTE)
                    # data %>%select(-c(PACIENTE,CatPeso))
ggpairs(bd_numericas_sexo, 
        mapping = aes(colour = SEXO, alpha=0.1),
        
        upper = list(continuous = wrap("cor", size = 2.5),
                     discrete = "blank", combo="blank"),
        #diag = list(continuous = wrap("barDiag")), # si quisiera graficar histogramas
        lower = list(combo = "box"), progress = F) +
        theme + labs(title= 'Descripci√≥n de variables num√©ricas en la base de datos', 
                     x='Variable', y='Variable') 
```


# 3) Caras de Chernoff

Este es un m√©todo propuesto por Chernoff (1973). 
B√°sicamente este an√°lisis transforma el valor de cada variable en una caracter√≠stica de una cara. Cuanto m√°s parecidas son las caras, es porque el vector de medias de un grupo es m√°s similar al vector de medias de otro grupo. 

En nuestro dataset, se van a comparar caras en funci√≥n de una nueva variable que incluye **categor√≠a de peso + sexo**.

```{r Chernoff}
# esto es equivalente en dplyr= bd_femenino <- data %>% filter (SEXO== 'F')
bd_fem <- data[data$SEXO == 'F',] 

bd_fem <- bd_fem[-c(1,3)]
bd_fem <- bd_fem %>% group_by(CatPeso) %>% 
          summarise(across(everything(), mean))
#Agreg0 '_F' al texto en la columna CatPeso
bd_fem <- bd_fem %>% mutate(CatPeso = paste0(CatPeso,'_F'))

bd_masc <- data[data$SEXO == 'M',] 
bd_masc <- bd_masc[-c(1,3)]
bd_masc <- bd_masc %>% group_by(CatPeso) %>% 
           summarise(across(everything(), mean))
bd_masc <- bd_masc %>% mutate(CatPeso= paste0(CatPeso,'_M'))

# Junto las bases de datos en una sola (rbind-> s√≥lo porque tienen las mismas columnas)
bd <- rbind(bd_fem,bd_masc)
# me quedo con todas las columnas menos cat peso
matriz <- as.matrix(bd[,-1])
rownames(matriz) <- bd$CatPeso # la info de cat peso va como nombre de fila de la matriz

head(matriz)

faces(matriz)# hace un gr√°fico con las caras de Chernoff
title("IMC infantil")
# Se pueden cambiar par√°metros de la funci√≥n [nrow.plot, ncol.plot, face.type]
faces(matriz,face.type = 2, ncol.plot = 4)
title("IMC infantil")
```

Como ver√°n, hay varios "estilos" para realizar este an√°lisis. En cualquier caso, el mismo sirve para realizar un an√°lisis visual r√°pido y determinar si hay poblaciones m√°s similares que otras.

# 4) Gr√°ficos de estrellas / radar plot

Existen dos tipos de gr√°ficos que son similares (radares y estrellas) que tambi√©n sirven para realizar una inspecci√≥n visual r√°pida de la distribuci√≥n de las variables en grupos que quiero comparar. 
En estos gr√°ficos las aristas apuntan a una variable determinada en el dataset, y el largo de esa arista indica el valor medio (o mediano, si se calcula).

A continuaci√≥n se presentan varias alternativas para realizar este an√°lisis.

```{r star_plot}
stars(matriz,full = T) #radius=F omite aristas
stars(matriz,full = T, draw.segments = T, cex = 0.7)
stars(matriz,full = T, cex = 0.7, len = 0.8, col.stars = terrain.colors(8),
      ncol = 4, main ='IMC infantil', key.loc = c(2.5,5.5),
      key.labels = colnames(matriz), xpd = T)
```


```{r radarplot}
normalize <- function(x, na.rm = TRUE) {return((x- min(x)) /(max(x)-min(x)))}

# me armo nueva base de ni√±os con CatPeso='OB'y normalizo ******

bd_OB <- data%>%filter(CatPeso == 'OB')
#creo variable 'SEXO'
SEXO <- bd_OB$SEXO        
#sapply sirve para aplicar una funci√≥n (en este caso "normalize") a la base de datos db_OB
bd_OB_n <- data.frame(sapply(bd_OB %>% select(-c(SEXO,PACIENTE,CatPeso)), normalize)) # los valores de cada columna quedan entre 0 y 1 

# Para poder usar radarplot, tengo que darle los l√≠mites del gr√°fico. 
# Como se realiz√≥ una normalizaci√≥n entre 0 y 1, pongo l√≠mite m√°x=1, min=0
max <- rep(1,6) #repito 6 veces, y obtengo vector de seis 1s (uno por cada variable)
min <- rep(0,6)

final <- cbind(SEXO,bd_OB_n) 
# calculo promedio de variables estandarizadas (agrupando por sexo)
final <- final %>% group_by(SEXO) %>% summarise(across(everything(), mean)) 
#armo data frame final, juntando las filas del max, min y medias para femenino y masculino
df_final <- data.frame(rbind(max, min, final[-1]))
rownames(df_final) <- c('max','min','Femenino','Masculino')
  
head(df_final)
# elijo colores en RGB (red/green/blue) indicando porcentaje de cada color. El cuarto n√∫mero se refiere a la transparencia
colors_in = c(rgb(0.97, 0.46, 0.42, 0.3), rgb(0, 0.78, 0.76, 0.3))
colors_border = c(rgb(0.97, 0.46, 0.42, 0.8), rgb(0, 0.78, 0.76, 0.8))

radarchart(df_final, axistype = 4, pcol = colors_border, pfcol = colors_in,cglcol = "grey",
           cglty = 5, axislabcol = "gray50", caxislabels = seq(0,1,5), cglwd = 0.6,
           vlcex = 0.8, calcex = 0.8, title = 'IMC infantil')

legend(x = 0.9, y = 1.3, legend = rownames(df_final[-c(1,2),]), bty = "n", pch = 20,
       col = colors_border , text.col = "darkgrey", cex = 0.8, pt.cex = 2)
```

# 5) Gr√°ficos de barras y mosaico

Un gr√°fico s√∫per utilizado en los an√°lisis exploratorios de datos multivariados es el gr√°fico de barras y los gr√°ficos mosaico. 

En el gr√°fico de barras se suelen expresar el n√∫mero o proporci√≥n de datos de los distintos niveles de una variable categ√≥rica.
En el gr√°fico de mosaico se puede representar el mismo tipo de data.


En el siguiente gr√°fico se presenta, en un gr√°fico de barras apilado, el n√∫mero absoluto de ni√±os que hay en cada sexo (eje x). Adem√°s, se agrega la informaci√≥n de la categor√≠a de peso (en las apiladas). Por √∫ltimo, se agregan los totales dentro de cada categor√≠a de sexo.

Si quisiera expresar la frecuencia relativa, y no el n√∫mero absoluto, podr√≠a agregar el par√°metro --> position = "fill" en la funci√≥n geom_bar(). 

```{r freq y barras}
# calculo cu√°ntos ni√±os hay de cada sexo
totales <- data %>% count (SEXO)

ggplot(data, aes(x = SEXO, fill = CatPeso)) + 
    geom_bar() + theme +  
  labs(title = 'Cantidad de ni√±os en cada categor√≠a de peso seg√∫n sexo', 
       x = 'Sexo', y = 'N√∫mero de ni√±os') + 
  scale_fill_viridis_d(name = 'Categor√≠a de peso') +
  geom_label(data = totales, aes(SEXO, 80, label = n, fill = NULL), 
             size = 3,show.legend = FALSE)

# si quisiera expresar la frecuencia relativa, y no el n√∫mero absoluto, podr√≠a agregar el par√°metro --> position = "fill" en la funci√≥n geom_bar().
```

A continuaci√≥n voy a transformar la variable cont√≠nua CC a una variable de 4 categor√≠as.

Luego usar√© esa nueva variable (que voy a llamar CC2), para poder graficar

```{r discretizaci√≥n}
quantile(data$CC)

data$CC2 <- cut(data$CC, 
                   breaks = c(-0.1,35,45,50,80), 
                   labels = c('[0-31)','[31-45)','[45-50)','[50-80)'))

tb <- table(data$CC2)
fr <- round(prop.table(tb)*100,2)
fr
```

En este gr√°fico se presenta la frecuencia relativa de CC (discretizado) seg√∫n la categor√≠a de peso de los ni√±os. 
Estoy analizando la relaci√≥n entre dos variables categ√≥ricas. 
A simple vista se puede observar que no parecen ser independientes porque en la categor√≠a D (de "Categor√≠a de Peso") tengo muchos valores de CC2 del intervalo [50-80], que parecen ir disminuyendo a medida que cambiamos de manera ordenada en los niveles de categor√≠a de peso.... OB no tiene observaciones con ese nivel de la variable, pero tiene muchos m√°s del nivel [0-31] (_podr√≠amos hacer un test de independencia chi cuadrado, por ej, para chequearlo_)

```{r freq}
totales_ <- data %>% count (CatPeso)

ggplot(data, aes(x = CatPeso, fill = CC2)) + 
    geom_bar(position = "fill") + theme +  
  labs(title = 'Frecuecia de ni√±os en cada categor√≠a de CC seg√∫n CatPeso', 
       x = 'Categor√≠a de Peso', y = 'Frecuencia relativa')+ 
  scale_fill_viridis_d(name = 'Intervalo CC')+
  theme(legend.key.size = unit(0.3, "cm"))+
  geom_label(aes(CatPeso, 1.05, label = n, fill = NULL), 
             size = 3, data = totales_,show.legend = FALSE)


```

Este mismo an√°lisis se puede reproducir en un gr√°fico de mosaico (fijens√© que son iguales!!)

```{r  mosaico}
ggplot(data=data) +
  geom_mosaic(aes(x = product(CatPeso, CC2), 
                  fill = CatPeso)) +
  theme + labs(title = 'Distribuci√≥n categor√≠a de peso\nseg√∫n √çndice CC',
              y = 'Categor√≠a de peso', x = 'Invervalo de √≠ndice CC') +
  scale_fill_viridis_d(name = 'Categor√≠a de peso') +
  theme(legend.position = 'none')

#mosaic_data <- table(data$CatPeso,data$CC2)
#mosaicplot(mosaic_data)
```


# 6) Gr√°ficos de puntos + densidad / histogramas

Otro tipo de gr√°ficos que pueden utilizarse para analizar la distribuci√≥n de **variables num√©ricas** son los scatter plot. 

Estos gr√°ficos analizar√°n la distribuci√≥n conjunta de 2 o 3 variables.

En el gr√°fico m√°s abajo se muestra la relaci√≥n de 2 variables. Adem√°s, se agregan las distribuciones marginales de cada una de estas variables por separado. Particularmente en este gr√°fico se agreg√≥ una 3er variable (categ√≥rica) que indica el sexo de las observaciones.

*Visualizaci√≥n de la relaci√≥n entre peso y cc en los datos nuevos*
```{r densidad y scatter}
plot1 <- ggplot(data, aes(x = as.numeric(CC), y = as.numeric(PESO), 
                                   color = SEXO)) +
  geom_point(aes(fill = SEXO),shape = 21, color = "black", size = 2, alpha = 0.4) + 
  scale_y_continuous(name = "Peso (Kg)") + 
  scale_x_continuous(name = "CC\nIndice cintura-cadera") + 
  theme_pubr() +
  theme(axis.title.y = element_text(size = 13, face="bold"), 
        axis.title.x = element_text(size = 13, face="bold"),
        legend.title = element_text(face = "bold"))+
  theme(legend.position = c(1, 1.2))

dens1 <- ggplot(data, aes(x = CC, fill = SEXO)) + 
  geom_density(alpha = 0.4) + 
  theme_void() + 
  theme(legend.position = "none")

dens2 <- ggplot(data, aes(x = PESO, fill = SEXO)) + 
  geom_density(alpha = 0.4) + 
  theme_void() + 
  theme(legend.position = "none") + 
  coord_flip()


dens1 + plot_spacer() + plot1 + dens2 + plot_layout(ncol = 2, nrow = 2,
                               widths = c(4, 1), heights = c(1, 4))

```

En el siguiente gr√°fico se realiza un an√°lisis de 3 variables num√©ricas

```{r 3d scatter}
col1 <- c('#F8766D','#00BFC4')
data_prueba <- data %>% mutate(GENERO = ifelse(SEXO == "F", 1, 2)) # F:1, M:2
col1 <- col1[as.numeric(data_prueba$GENERO)]


scatterplot3d(data_prueba$CC,data_prueba$IMC,data_prueba$PESO,
              color = alpha(col1,0.3), box=F,angle=45, pch = 19,
              grid = TRUE, tick.marks = FALSE, xlab = "CC",
              ylab = "IMC", zlab = "PESO", main ='3D plot')

legend("topright", bty = "n", cex = .9, title = "Sexo",
       c("Femenino", "Masculino"),
       fill = c('#F8766D','#00BFC4'))

```


# 7) Curvas de nivel

Las curvas de nivel son otro tipo de estrategia utilizada para representar los valores de variables num√©ricas. 
Aqu√≠ se representan sobre valores sint√©ticos, pero tambi√©n podr√≠an utilizarse con los datos que presentamos en esta notebook. 

Los gr√°ficos de nivel suelen utilizarse para representar la coocurrencia de distintos valores de dos variables. 

<span style="color:blue"> Datos sint√©ticos </span>
```{r nivel}
x=y=seq(-4*pi,4*pi,len = 27)
r=sqrt(outer(x^2,y^2,"+"))
filled.contour(r,axes = FALSE) # grafica las curvas de nivel del cono dado por la funci√≥n r
filled.contour(exp(-0.1*r), frame.plot=FALSE, plot.axes={}) # grafica las curvas de nivel del cono dado por la funci√≥n exp(-0.1*r)

# lo mismo en ggplot:https://r-charts.com/es/correlacion/contour-ggplot2/
```

Ahora miramos nuestros datos

<span style="color:blue"> Datos de peso que ven√≠amos usando </span>
```{r nivel2}
ggplot(data, aes(x = as.numeric(CC), y = as.numeric(PESO))) +
  geom_density_2d()+theme

```

# 8) Gr√°fico de coordenadas paralelas / perfiles (ejemplo, perfiles medios calculados previamente)

En las siguientes figuras se muestran gr√°ficos de coordenadas paralelas.

Los datos tratan de disintos postulantes a una entrevista que fueron puntuados para 3 caracter√≠sticas (cordialidad, presencia e idioma) por 2 jueces distintos.
Cada juez puntua a cada postulante... para evitar sesgos particulares de un dado juez (por ejemplo, que sea muy "positivo" y ponga todos los puntajes muy altos o la inversa para un juez muy "negativo") se estandarizan los puntajes de cada postulante dentro por juez [*de este modo, el peor postulante para la variable "cordialidad" puede compararse entre jueces, por ejemplo*].

Los gr√°ficos de coordenadas paralelas muestran el valor que adquiere cada observaci√≥n (postulante) para las 3 variables medidas. Esto se hace para cada juez (es decir, se van a ver tantas l√≠neas como observaciones tengamos).

Si se grafican perfiles (vectores medios), entonces voy a tener una curva por cada juez o una curva por cada variable (dependiendo c√≥mo agrupo y se grafico perfiles fila o perfiles columna).


## **Cargo datos**
<span style="color:blue"> BD de entrevistas recepcionistas </span>
```{r coordenadas paralelas}
#gr√°fico de coordenadas paralelas
url2 <- 'https://docs.google.com/spreadsheets/d/1uQ6uq_qaoUBNHhskRM1iIGhZUu-2E84f'
bd_recepcionistas <- gsheet2tbl(url2)
head(bd_recepcionistas)

# Transformaci√≥n de escalado (x-mean/sd) por fila (por candidato): 
# todas las variables est√°n normalizadas por cada candidato, y en este caso, separado de cada juez
recep_st <- scale(t(bd_recepcionistas[,-c(1,5)]), center=T, scale=TRUE)
apply(t(recep_st), 1, mean) # chequeo que las 12 filas (6 cand. x 2 jueces) tengan media cero  (desv√≠o 1)
recep_st <- data.frame(t(recep_st))
# agrego cols candidatos y jueces
recep_st$candidatos <- bd_recepcionistas$candidatos
recep_st$juez <- factor(bd_recepcionistas$juez)
```

```{r perfiles}
# Gr√°fico de coordenadas paralelas
ggparcoord(data = recep_st, scale = 'globalminmax', # ‚Üí Sin escalado
           columns = 1:3, alphaLines = 0.4, groupColumn = 5) +
  theme + ggtitle("Gr√°fico de coordenadas paralelas") +
  xlab('Variable') + ylab('Valor estandarizado')

# Gr√°fico de perfiles (puntaje promedio que cada juez di√≥ en cada variable)

head(bd_recepcionistas)

df_perfiles <- bd_recepcionistas[2:5] %>% group_by(juez) %>% summarise_all(mean)
df_perfiles$juez <- factor(df_perfiles$juez)

ggparcoord(data = df_perfiles, columns=2:4, scale='globalminmax', groupColumn = 1) + 
  #globalminmax ‚Üí Sin escalado
  theme + ggtitle("Comparaci√≥n de puntajes por Juez\nseg√∫n gr√°fico de perfiles") +
  xlab('Variable') + ylab('Valor medio')
```

```{r comparaci√≥n de perfiles de variables}
head(recep_st)

recep_st2 <- recep_st %>% 
  pivot_longer(!c(candidatos,juez), names_to = "Variable", values_to = "valor")

head(recep_st2)

ggplot(data = recep_st2, aes(x = candidatos, y = valor, color = Variable, group = Variable)) +
  geom_point() + facet_grid(~juez) + theme + 
  theme(legend.position='bottom') + geom_line() +
  labs(title = 'Comparaci√≥n de perfiles de variables seg√∫n juez',
       y = 'Valor estandarizado', x = 'Postulante')
```

As√≠ como se grafic√≥ un perfil medio (s√≥lo una curva), yo podr√≠a tener una intuici√≥n no s√≥lo de la media, sino que tambi√©n podr√≠a mirar la distribuci√≥n general o la mediana, por ejemplo. Para ello podr√≠an utilizar boxplots (la caja representa el rango intercuartil q25-q75, luego se grafica la mediana (l√≠nea m√°s gruesa), y se grafican los "bigotes" que muestran los l√≠mites de la distribuci√≥n. Los outliers son aquellas observaciones extremas que aparecen como c√≠rculos por encima o debajo de los bigotes [*whiskers*]).

En los siguientes gr√°ficos se representan boxplots de la distribuci√≥n de cada variable. 

<br/>
<span style="color:blue"> BD de IMC infantil </span>

```{r Transformaci√≥n por columna}
head(data)

data_st <- data %>% select (-c(1,3,9,10)) %>% summarise_all(scale)
data_st$PACIENTE <- data$PACIENTE

head(data_st)

boxplot(data_st[1:6], col=terrain.colors(6), cex.axis=0.6, ylab="", main="Datos biom√©tricos")

data_st1 <- data_st %>% pivot_longer(!PACIENTE, names_to ='Variable', values_to = 'Valores')

ggplot(data= data_st1, aes(y = Valores, x = Variable, color = Variable, fill = Variable,alpha=0.2)) +
  geom_boxplot() + theme + theme(legend.position='none') +
  scale_fill_viridis_d(option = 'inferno') + scale_color_viridis_d(option = 'inferno') + 
  labs(title='Variables estandarizadas (por columna)') +
  geom_hline(yintercept = c(-1,1), linetype = "dotted", color = 'gray60')

#Chequeo
mean(data_st$EDAD)
sd(data_st$EDAD)
```

# 9) Alternativas robustas

Muchas veces la distribuci√≥n de las variables tiene presencia de outliers o valores muy extremos que no se corresponden con la distribuci√≥n general. 

Algunos de los estad√≠sticos que calculamos previamente son muy sensibles a la presencia de outliers (es decir, cambian mucho por s√≥lo la presencia de este/os outlier/s), por lo cu√°l no representan fielmente la distribuci√≥n y deber√≠an ser reemplazados por otro tipo de estad√≠stico. 

Ejemplo de esto √∫ltimo es la media. 
Si yo calculo la media de los valores [1,1,1,1,2,1,1,0,1,1] ser√° = 1, pero si le cambio un valor por un outlier ser√° muy distinto: ej [1,1,1,1,2,1,1,0,1,1000] aprox 100 !!!

Para mitigar este efecto, es necesario trabajar con otro tipo de estad√≠sticos o estrategias. 

<br/>
A continuaci√≥n se presentan 3 estategias posibles:

1- Usar medianas en vez de medias.
2- Remover outliers seg√∫n ajuste a la distribuci√≥n chi cuadrado cuando calculo distancia de Mahalanobis de todos los puntos.
3- Usar estrategias que no consideren todos los datos, sino los "centrales".

<br/>
Genero datos arficiales a partir de una distribuci√≥n normal. Despu√©s le agrego un par de outliers y grafico la distribuci√≥n.
Estos datos son normales (puntos verdes) o tienen outliers (poblaci√≥n roja)

```{r robust,warning=F, message=F, warn.conflicts=FALSE}
library(MASS)
set.seed(0)
bivariate_data <- as.data.frame(mvrnorm(n = 150,mu = c(0, 0),
                                        Sigma = matrix(c(5, 3, 4, 4), ncol = 2)))
bivariate_data$V1 <- scale(bivariate_data$V1)
bivariate_data$V2 <- scale(bivariate_data$V2)
colnames(bivariate_data) <- c('V1','V2')
bivariate_data$nor <- 'si'

bivariate_data2 <- data.frame(scale(data$CC),scale(data$PESO))
bivariate_data2$nor  <- 'no'
colnames(bivariate_data2) <- c('V1','V2','nor')

bivariate_data3 <- rbind(bivariate_data, bivariate_data2)


plot2 <- ggplot(bivariate_data3, aes(x = V1, y = V2, 
                                   color = nor)) +
  geom_point(aes(fill=nor ),shape = 21, color = "black", size = 2, alpha=0.4) + 
  scale_y_continuous(name = "Variable 2") + 
  scale_x_continuous(name = "Variable 1") + 
  theme_pubr() +
  theme(axis.title.y = element_text(size = 13, face = "bold"), 
        axis.title.x = element_text(size = 13, face = "bold"),
        legend.title = element_text(face = "bold"))+
  theme(legend.position = c(1, 1.2))

dens3 <- ggplot(bivariate_data3, aes(x = V1, fill = nor )) + 
  geom_density(alpha = 0.4) + 
  theme_void() + 
  theme(legend.position = "none")

dens4 <- ggplot(bivariate_data3, aes(x = V2, fill = nor )) + 
  geom_density(alpha = 0.4) + 
  theme_void() + 
  theme(legend.position = "none") + 
  coord_flip()


dens3 + plot_spacer() + plot2 + dens4 + plot_layout(ncol = 2, nrow = 2,
                               widths = c(4, 1), heights = c(1, 4))
```




## A - Vector de medianas

Si analizo la poblaci√≥n verde (sin outliers), se ver√° que el vector de medias (triangulo verde) y el vector de medianas (triangulo negro invertido) son muy similares. En ambos casos se encuentran centrados en la distribuci√≥n de las variables 1 y 2 (mis variables generadas artificialmente).
```{r vectores2}
# me quedo s√≥lo con las variables num√©ricas
vector_medias <- apply(bivariate_data[,1:2], 2, mean) 
vector_medias_nonorm <- apply(bivariate_data2[,1:2], 2, mean) 
vector_medianas<- apply(bivariate_data[,1:2], 2, median) 
vector_medianas_nonorm<- apply(bivariate_data2[,1:2], 2, median) 

tablita <- as.data.frame(rbind(vector_medias,vector_medias_nonorm,vector_medianas,vector_medianas_nonorm))
head(tablita)
```

Si ahora grafico lo que sucede con la poblaci√≥n roja, la que ten√≠a un outlier, se puede ver que ahora el vector de media y mediana ya no son tan coincidentes. El de medias (triangulo rojo) est√° m√°s corrido hacia donde se encuentra el outlier, y no est√° tan centrado con la distribuci√≥n.

```{r grafico1}
ggplot(bivariate_data, aes(x = V1, y = V2)) +
  geom_point(shape = 21, color = 'black',fill = '#00BFC4', size = 2, alpha=0.4) + 
  scale_y_continuous(name = "Variable 2") + 
  scale_x_continuous(name = "Variable 1") + 
  theme+
  theme(legend.position = c(1, 1.2)) + labs(title= 'Scatter plot datos normales')+
  annotate("point", x = vector_medias[1], y = vector_medias[2], colour = "black", fill='#117d80', shape=24, size=3)+
  annotate("point", x = vector_medianas[1], y = vector_medianas[2], colour = "black", fill='black', shape=25, size=3)

```

```{r grafico2}
ggplot(bivariate_data2, aes(x = V1, y = V2)) +
  geom_point(shape = 21, color = "black", size = 2, alpha=0.4, fill='#F8766D') + 
  scale_y_continuous(name = "Variable 2") + 
  scale_x_continuous(name = "Variable 1") + 
  theme+
  theme(legend.position = c(1, 1.2)) + labs(title= 'Scatter plot datos no normales')+
  annotate("point", x = vector_medias_nonorm[1], y = vector_medias_nonorm[2], colour = "black", fill='#d13c32', shape=24, size=3)+
  annotate("point", x = vector_medianas_nonorm[1], y = vector_medianas_nonorm[2], colour = "black", fill='black', shape=25, size=3)

```


## B - Distancia Mahalanobis

Ahora calculamos distancia de mahalanobis de las dos poblaciones que hab√≠amos definido previamente (la verde y la roja).

Si graficamos la distribuci√≥n de las distancias vemos que la poblaci√≥n roja tiene valores m√°s extremos de distancia. Posiblemente esos datos m√°s extremos sean outliers.

```{r mahalanobis}
bivariate_data$mahalanobis <- mahalanobis(bivariate_data[,1:2],
                                          colMeans(bivariate_data[,1:2]),
                                          cov(bivariate_data[,1:2]))

bivariate_data2$mahalanobis <- mahalanobis(bivariate_data2[,1:2], 
                                           colMeans(bivariate_data2[,1:2]),
                                           cov(bivariate_data2[,1:2]))

bivariate_data3 <- rbind(bivariate_data,bivariate_data2)

ggplot(bivariate_data3, aes(x = mahalanobis, color = nor, fill = nor)) + 
  geom_histogram(position = 'identity',alpha = 0.3) + theme +
  labs(title = 'Distancia Mahalanobis', x = 'Distancia mahalanobis', y = 'Cantidad')

#k=n√∫mero de variables
#data$pvalue <- pchisq(data$mahalnobis, df=k-1, lower.tail=FALSE)
#p-valor<0.001 son considerados outliers
```

## C - MVE /  MCD

Por √∫ltimo vamos a presentar el c√≥digo para realizar MVE (Minimum Volume Ellipsoid) o MCD (Minimum Covariance Determinant).

- MVE: El MVE busca un elipsoide de volumen m√≠nimo con dos restricciones: (1) Que el elipsoide debe contener ‚Ñé puntos en su interior uni√≥n su frontera, y (2) el elipsoide debe contener al menos ùëù+1 puntos en su frontera.
- MCD: El MCD es matem√°ticamente equivalente a encontrar un elipsoide de volumen m√≠nimo con solo una restricci√≥n, a saber, que el elipsoide debe contener ‚Ñé puntos en su interior uni√≥n su frontera.

Ambos m√©todos calculan vectores de posici√≥n y escala pero **no consideran todos los datos**... es decir, calculan usando los datos pero tratando de dejar por fuera a los outliers.

```{r MVE-MCD,warning=F, message=F, warn.conflicts=FALSE}
library(rrcov)
CovMve(bivariate_data[,1:2], alpha = 0.7, nsamp = 100, seed = NULL, trace = FALSE)
CovMve(bivariate_data2[,1:2], alpha = 0.7, nsamp = 100, seed = NULL, trace = FALSE)

# alpha= par√°metro num√©rico que controla el tama√±o de los subsets sobre el cu√°l se calcula el determinante. Va entre 0.5-1
# nsamp= n√∫mero de subsets para estimadores iniciales. Pueden ser valores num√©ricos o poner "best"/"exact" (ojo que ac√° tarda)

library(robustbase)
covMcd(bivariate_data[,1:2])
```